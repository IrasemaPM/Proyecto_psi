[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "El valor optimo del indice de comportamiento",
    "section": "",
    "text": "Prefacio\nEn este libro se desarrollara el proyecto de la clase de Aprendizaje Reforzado.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introdución",
    "section": "",
    "text": "En la literatura existen una variedad de modelos en los cuales consideran la vacunación como medida de prevención para el control de enfermedades [Jorge, y mas modelos]. Sin embargo, este medio de control llega a presentar algunas fallas como son: la falla de grado, falla en la toma y falla en la duración [Maclean]. En la modelación de enfermedades respiratorias con ecuaciones diferenciales, se suele considerar que las vacunas tienen una falla tipo de grado [Jorge y mas modelos]. Por otro lado, Pedroza, et. el, proponen un modelo de ecuaciones diferenciales donde consideran que la vacuna tiene dos tipos de fallas: la falla de grado y la falla en la toma.\nEn este ultimo trabajo, proponen un índice de comportamiento (\\(\\psi\\)) el cual permite medir que tan riguroso pueden seguir las medidas de prevención una vez que son vacunados. En el modelo que proponen este índice solo afecta a los vacunados no inmunes",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdución</span>"
    ]
  },
  {
    "objectID": "Formulacion.html",
    "href": "Formulacion.html",
    "title": "2  Formulación del Proceso de Decisión de Markov",
    "section": "",
    "text": "Los estados de nuestro proceso de decisión de Markov representarán la proporción de la población en cada categoría del modelo propuesto por XXX:\n\n\\(S_{t}\\): Fracción de susceptibles en el tiempo \\(t\\).\n\\(V_{+t}\\): Fracción de vacunados inmunes en el tiempo \\(t\\).\n\\(V_{-t}\\): Fracción de vacunados no inmunes en el tiempo \\(t\\).\n\\(I_{t}\\): Fracción de infectados en el tiempo \\(t\\).\n\\(R_{t}\\): Fracción de recuperados en el tiempo \\(t\\).\n\nEl estado global del sistema en el tiempo \\(t\\) se presenta como\n\\[\nx_{t} = (S_{t}, V_{+t}, V_{-t}, I_{t}, R_{t})\n\\]\nEl escenario que consideraremos para cada \\(t \\in {0,1,\\dots, N}\\)para el proceso de Markov:\n\n\\(x_{t}\\): representa la dinámica de la enfermedad en el tiempo \\(t\\).\n\\(a_{t}\\): representa en qué escenario del índice de comportamiento se encuentra la población en el tiempo\\(t\\).\n\nAlgunos supuestos que estaremos considerando para nuestro proceso son:\n\nLas personas cambian su comportamiento en el tiempo \\(t\\) de forma instantánea.\nLas únicas personas que pueden cambiar su comportamiento son los vacunados no inmunes.\nSupondremos que las personas cambian su comportamiento bajo una distribución uniforme \\([0.5, 2]\\).\n\nBajo los supuestos anteriormente mencionados, consideramos el siguiente Modelo de Control de Markov.\n\\[\n(\\mathbf{X},  \\{A(x): x \\in X\\}, \\mathbf{P}, \\mathbf{C})\n\\]\ndonde \\(\\mathbf{X}\\) es el espacio de los estados, \\(\\{A(x): x \\in X\\}\\) es el espacio de las acciones admisibles, \\(\\mathbf{P}\\) es la ley de transicion de modelo y \\(\\mathbf{C}\\) es la funcion de costo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Formulación del Proceso de Decisión de Markov</span>"
    ]
  }
]